{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "ec45298d-3f37-40b0-86da-25367e8236cb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession # Puerta de entrada para trabajar con spark <-- SIEMPRE DEBEMOS IMPORTAR LA LLAVE MAESTRA QUE INICIA TODO.\n",
    "from pyspark.sql.functions import *  # Funciones propias del módulo SQL de Spark, para trabajar sobre Dataframes.\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder.appName(\"EjerciciosRDDsApacheSparkDatabricks\").getOrCreate() \n",
    "\"\"\"\n",
    "^          ^__________^        ^_________^                               ^\n",
    "|                |                   |                                   | \n",
    "Variable   Constructor de Sesión   Nombre Aplicación       Evita conflicto del SparkSession\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "302cc5ad-31d8-4760-88e3-0bfae582ab77",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### RDDs (Versión Databricks Community Edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "c123e191-0c0e-475a-b876-f2d5b15c7dc6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Link de Databrick Community (Solo para el ejercicio de RDDs): [Databrick Community](https://community.cloud.databricks.com/?o=2956217321084781)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "e1da7c27-5fa6-44fa-b46e-b2fe6e708266",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### EJERICICIOS RDDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "cc130af6-ecb5-4eb5-81dd-7183fc5329e6",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# EJERCICIOS BÁSICOS DE APACHE SPARK - RDDs\n",
    "\n",
    "# 1. \n",
    "dias_semana = [\"Lunes\", \"Martes\", \"Miércoles\", \"Jueves\", \"Viernes\", \"Sábado\", \"Domingo\"]\n",
    "rdd_dias_semana = spark.sparkContext.parallelize(dias_semana)\n",
    "print(rdd_dias_semana.collect())\n",
    "\n",
    "# 2.\n",
    "numeros = [1,2,3,4,5,6,7,8,9,10]\n",
    "rdd_numeros = spark.sparkContext.parallelize(numeros)\n",
    "print(rdd_numeros.count())\n",
    "\n",
    "# 3. \n",
    "ciudades = [\"Paris\",\"Shangai\",\"Roma\",\"Buenos Aires\"]\n",
    "rdd_ciudades = spark.sparkContext.parallelize(ciudades)\n",
    "print(rdd_ciudades.first())\n",
    "\n",
    "# 4.\n",
    "numeros = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "numeros_rdd = spark.sparkContext.parallelize(numeros)\n",
    "print(numeros_rdd.take(5))\n",
    "\n",
    "# 5.\n",
    "numeros = [1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20]\n",
    "rdd_numeros = spark.sparkContext.parallelize(numeros)\n",
    "print(rdd_numeros.filter(lambda x:x%2==0).collect())\n",
    "\n",
    "# 6.\n",
    "numeros = [1,2,3,4,5]\n",
    "rdd_numeros = spark.sparkContext.parallelize(numeros)\n",
    "rdd_cuadrados = rdd_numeros.map(lambda x:x**2)\n",
    "print(rdd_cuadrados.collect()) \n",
    "\n",
    "# 7.\n",
    "frases = [\"Hola mundo\", \"Spark es genial\", \"RDDs son poderosos\"]\n",
    "rdd_frases = spark.sparkContext.parallelize(frases)\n",
    "print(rdd_frases.flatMap(lambda x:x.split(\" \")).collect())\n",
    "\n",
    "# 8.\n",
    "numeros = [1,2,3,4,5,6,7,8,9,10]\n",
    "rdd_numeros = spark.sparkContext.parallelize(numeros)\n",
    "print(rdd_numeros.reduce(lambda x,y:x+y))\n",
    "\n",
    "# 9.\n",
    "lista_tuplas = [(\"a\", 1), (\"b\", 2), (\"a\", 3), (\"b\", 4), (\"c\", 5)]\n",
    "rdd_lista_tuplas = spark.sparkContext.parallelize(lista_tuplas)\n",
    "print(rdd_lista_tuplas.reduceByKey(lambda x,y:x+y).collect())\n",
    "\n",
    "# 10.\n",
    "frases = [\"Hola mundo\", \"Spark es genial\", \"RDDs son poderosos\"]\n",
    "rdd_frases = spark.sparkContext.parallelize(frases)\n",
    "flat_map_frases = rdd_frases.flatMap(lambda x:x.split(\" \"))\n",
    "print(f\"Cantidad de  palabras mayor a 4 letras: {flat_map_frases.filter(lambda x:len(x)>4).count()}\")\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "02_Ejercicios_RDDs_Spark_Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
