{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e9da7a8e-d608-4e9b-8c64-8aae3312b040",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession # Puerta de entrada para trabajar con spark <-- SIEMPRE DEBEMOS IMPORTAR LA LLAVE MAESTRA QUE INICIA TODO.\n",
    "from pyspark.sql.functions import *  # Funciones propias del módulo SQL de Spark, para trabajar sobre Dataframes.\n",
    "from pyspark.sql.types import *\n",
    "spark = SparkSession.builder.appName(\"DataframesApacheSparkDatabricks\").getOrCreate() \n",
    "\"\"\"\n",
    "^          ^__________^        ^_________^                               ^\n",
    "|                |                   |                                   | \n",
    "Variable   Constructor de Sesión   Nombre Aplicación       Evita conflicto del SparkSession\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d343ce83-6287-4a94-ae88-f26b9c2a69fb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### DATAFRAMES (Versión Databricks Free Edition)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "6aa4db57-5b8c-49ba-a95b-d8631543a520",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "#### Link de [Databrick Free Edition](https://dbc-89f542f8-2df6.cloud.databricks.com/?o=758509963140561)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "9b7c871d-ed5f-41ff-b636-71cd5ff6762c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "Los DataFrames son una abstracción de alto nivel sobre los RDDs. A diferencia de los RDDs (que son colecciones distribuidas sin estructura), los DataFrames sí cuentan con nombres de columnas y tipos definidos, lo que los convierte en una estructura similar a una tabla relacional o un DataFrame de Pandas."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "84e69415-22cf-4ecb-a564-9a306819ec59",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "##### DEFINICIÓN DE UN DATAFRAMES EN DATABRICKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b7819ea7-2cbd-414b-9ee7-0380325fd629",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 1️⃣ DEFINIR DATAFRAMES DESDE CERO EN APACHE SPARK - DATABRICKS:\n",
    "\n",
    "    #✴️ Parámetros de createDataframe(): data= *Datos en formato de tupla* y schema= *Nombre de las columnas*\n",
    "\n",
    "datos = [(\"Brayan\",21),(\"Rafael\",22)] # ⬅️ Lista de tuplas (Cada tupla es un registro en el Dataframe)\n",
    "df = spark.createDataFrame(data=datos,schema=[\"Nombre\",\"Edad\"]) #⬅️ Definimos el Dataframe (spark.createDataframe)\n",
    "# df.head()     ##⬅️ Muestra el primer registro del Dataframe\n",
    "df.show()   ##⬅️ Muestra todo los registros del Dataframe (Límite de 20 filas)\n",
    "# df.tail(3)  ##⬅️ Muestra los 3 últimos registros del Dataframe en una sola fila."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d52f3e7b-ee4a-4846-8ce9-1d8539fcb81d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# 2️⃣ DEFINIR DATAFRAMES EN APACHE SPARK MEDIANTE UN DICCIONARIO:\n",
    "\n",
    "diccionario = {\"Nombre\":[\"Brayan\",\"Rafael\"],\"Edad\":[21,22]} # ⬅️ Diccionario\n",
    "df_dict = spark.createDataFrame(data=list(zip(*diccionario.values())),schema=list(diccionario.keys()))\n",
    "\"\"\"\n",
    "    Vamos descomponiendo y explicando todo lo que sucede en data de este dataframe.\n",
    "    Paso 1. diccionario.values(): Retorna todos los valores asignados a una llave en el diccionario. \n",
    "                                  ➡️ [\"Brayan\",\"Rafael\"];[21,22]\n",
    "    2. * : Este asterisco desempaqueta cada valor retornado del Paso 1. \n",
    "                                  ➡️ \"Brayan\",21   ||   \"Rafael\",22\n",
    "    3. zip(): Unifica los valores desempaquetados del Paso 2. en una tupla.\n",
    "                                  ➡️ (\"Brayan\",21),(\"Rafael\",22)\n",
    "    4. list(): Convierte cada tupla retornada del Paso 3. y lo asigan como un elemento ed una lista final.\n",
    "                                  ➡️[(\"Brayan\",21),(\"Rafael\",22)]\n",
    "    5. data: El parámetro de createDataFrame() lo toma como valores correctamente organizados para ser parte de los registros del dataframe.                                 \n",
    "\"\"\" \n",
    "df_dict.show()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "2"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "03_DataFrames_Spark_Databricks",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
